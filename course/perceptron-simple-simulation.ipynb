{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The perceptron - a simple simulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>Table of contents</div>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by implementing a very simple network. Our network will only have two input units plus a bias unit, as in the figure. \n",
    "The network will learn to categorize few different input patterns as belonging or not to a class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "#### Initializing data and parameters\n",
    "In this example we will create input data with pseudo-random number generation.\n",
    "We will start from two points, the centroids, and create all patterns in each group (belonging/not belonging) adding noise to each centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Training\n",
    "\n",
    "\n",
    "# Constants\n",
    "\n",
    "# Number of input elements\n",
    "n = 2        \n",
    "\n",
    "# Learning rate\n",
    "eta = 0.0001 \n",
    "\n",
    "# number of training patterns\n",
    "n_patterns = 2000\n",
    "\n",
    "# Number of repetitions of \n",
    "# the pattern series\n",
    "epochs = 4\n",
    "\n",
    "# Number of timesteps\n",
    "stime = n_patterns*epochs\n",
    "\n",
    "\n",
    "# Variables\n",
    "\n",
    "# generate training data (function build_dataset in utils.py)\n",
    "data = build_dataset(n_patterns)\n",
    "\n",
    "# Each row of P is an input pattern\n",
    "P = data[:,:2]\n",
    "\n",
    "# Each element of o is the desired output \n",
    "# relative to an input pattern\n",
    "o = data[:,2]\n",
    "\n",
    "# Initialize weights\n",
    "w = zeros(n+1)\n",
    "\n",
    "# Initialize the weight history storage\n",
    "dw = zeros([n+1,stime])\n",
    "\n",
    "# Initialize the error history storage\n",
    "squared_errors = zeros(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the input points. Red points belong to the class to be learned, while blue ones do not belong to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# limits\n",
    "upper_bound = P.max(0) + 0.2*(P.max(0)-P.min(0))\n",
    "lower_bound = P.min(0) - 0.2*(P.max(0)-P.min(0))\n",
    "\n",
    "\n",
    "# Create the figure\n",
    "fig = figure(figsize=(4,4))\n",
    "\n",
    "scatter(*P[(n_patterns/2):,:].T, s = 50,  c = '#ff8888' )\n",
    "scatter(*P[:(n_patterns/2),:].T, s = 50,  c = '#8888ff' )\n",
    "\n",
    "xlim( [lower_bound[0], upper_bound[0]] )\n",
    "ylim( [lower_bound[1], upper_bound[1]] )\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spreading of the network during training\n",
    "Here starts the core part, iterating the timesteps. We also divide the training phase in epochs. Each epoch is a single presentation of the whole input pattern series. The sum of squared errors will be grouped by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of pattern indices.\n",
    "# We will reshuffle it at each \n",
    "# repetition of the series\n",
    "pattern_indices = arange(n_patterns)\n",
    "\n",
    "# counter of repetitions \n",
    "# of the series of patterns\n",
    "epoch = -1\n",
    "\n",
    "for t in xrange(stime) :\n",
    "    \n",
    "    # Reiterate the input pattern \n",
    "    # sequence through timesteps\n",
    "    \n",
    "    # Reshuffle at the end \n",
    "    # of the series\n",
    "    if t%n_patterns == 0:\n",
    "        shuffle(pattern_indices)\n",
    "        epoch += 1\n",
    "        \n",
    "    # Current pattern \n",
    "    k = pattern_indices[t%n_patterns]\n",
    "    \n",
    "    # MAIN STEP CALCULATIONS\n",
    "     \n",
    "    # Bias-plus-input vector\n",
    "    x = hstack([1, P[k]])\n",
    "    \n",
    "    # Weighted sum - !!dot product!!\n",
    "    net = dot(w, x)\n",
    "    \n",
    "    # Activation\n",
    "    y = step(net)\n",
    "    \n",
    "    # Learning\n",
    "    w += eta*(o[k] - y)*x\n",
    "       \n",
    "    # Store current weights\n",
    "    dw[:,t] = w\n",
    "    \n",
    "    # Current error\n",
    "    squared_errors[epoch] += 0.5*(o[k] - y)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the results of training\n",
    "We plot the final decision boundary together with the history of the squared errors through epocs.\n",
    "As you see below, the network finds a line that completely divides points belonging to the class from those not belonging to it. The gray lines are previous attempts to define the boundary which led to an error greater than zero. The curve of the error goes to zero at the third epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "fig = figure(figsize=(10,4))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.set_title('Decision boundary')\n",
    "\n",
    "# Chose the x-axis coords of the\n",
    "# two points to plot the decision \n",
    "# boundary line\n",
    "x1 = array([lower_bound[0],upper_bound[0]])\n",
    "\n",
    "# Calculate the y-axis coords of the\n",
    "# two points to plot the decision \n",
    "# boundary line as it changes \n",
    "for t in xrange(stime) :\n",
    "    \n",
    "    # Show evert 10th timestep\n",
    "    if t%10 == 0:\n",
    "        \n",
    "        if dw[2,t] != 0 :\n",
    "            # Evaluate x2 based on current weights\n",
    "            x2 = -(dw[1,t]*x1 + dw[0,t])/dw[2,t]\n",
    "        \n",
    "            # Plot the changes in the boundary line during learning\n",
    "            ax.plot(x1,x2, c='#cccccc', linewidth = 1, zorder = 1)\n",
    "\n",
    "# Evaluate x2 ibased on final weights\n",
    "x2 = -(w[1]*x1 + w[0])/w[2]\n",
    "\n",
    "# Plot the learned boundary line\n",
    "plot(x1,x2, c= '#000000', linewidth = 2, zorder = 1)\n",
    "\n",
    "# Plot in red points belonging to the class\n",
    "scatter(*P[(n_patterns/2):,:].T, s = 50,  c = '#ff8888', zorder = 2 )       \n",
    "# Plot in blue points not belonging to the class \n",
    "scatter(*P[:(n_patterns/2),:].T, s = 50,  c = '#8888ff', zorder = 2 )\n",
    "\n",
    "# Limits and labels of the plot\n",
    "xlim( [lower_bound[0], upper_bound[0]] )\n",
    "ylim( [lower_bound[1], upper_bound[1]] )\n",
    "xlabel(\"$p_1$\", size = 'xx-large')\n",
    "ylabel(\"$p_2$\", size = 'xx-large')\n",
    "\n",
    "# Plot squared errors\n",
    "ax = fig.add_subplot(122)\n",
    "ax.set_title('Error')\n",
    "ax.plot(squared_errors)\n",
    "\n",
    "# Labels and ticks of the plot\n",
    "xlabel(\"epochs\", size = 'xx-large')\n",
    "ylabel(\"SSE\", size = 'xx-large')\n",
    "xticks(range(epochs)) \n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "#### Initializing data and parameters\n",
    "We now create a new dataset to test the network by generating a cloud of random points allover the space of inputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Test\n",
    "\n",
    "# Number of test patterns\n",
    "n_patterns = 50000\n",
    "\n",
    "# Generating test data - we use a single repeated centroid\n",
    "# so we have a single population of points expanding across\n",
    "# the decision boundary line  \n",
    "test_centroid = lower_bound +(upper_bound-lower_bound)/2.0\n",
    "\n",
    "# Generating test data - build_dataset function from utils.py. \n",
    "# We change the standard deviation \n",
    "data = build_dataset(n_patterns, \n",
    "                      centroids1 = [ test_centroid ], # we use the same centroids for class \n",
    "                      centroids2 = [ test_centroid ], # and non-class\n",
    "                      std_deviation = 2.6 ) # we want the test samples  \n",
    "                                            # to be sparsely distributed\n",
    "\n",
    "# Each row of P is a test pattern\n",
    "P = data[:,:2]\n",
    "\n",
    "# Create the figure\n",
    "fig = figure(figsize=(5,4))\n",
    "\n",
    "title('Tests - average error = {}'.format(mean(squared_errors).round(4)))\n",
    "\n",
    "# Show points\n",
    "ax = scatter(*P.T, s = 2,  edgecolors='none', zorder = 2  )\n",
    "\n",
    "xlim( [lower_bound[0], upper_bound[0]] )\n",
    "ylim( [lower_bound[1], upper_bound[1]] )\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying the input patterns\n",
    "We read each pattern and collect the answer of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "y = zeros(n_patterns)\n",
    "\n",
    "# iterate tests\n",
    "for t in xrange(n_patterns) :\n",
    "    \n",
    "    # Bias-plus-input vector\n",
    "    x = hstack([1, P[t]])\n",
    "    \n",
    "    # Weighted sum - !!dot product!!\n",
    "    net = dot(w, x)\n",
    "    \n",
    "    # Activation\n",
    "    y[t] = step(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the results of test\n",
    "We can plot all test patterns using the output of the network to color them. Red and blue dots correspond to patterns belonging or not belonging to the class. You can see that the network divided all inputs into two groups with a linear separation. This division is a generalization of that given with the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the figure\n",
    "fig = figure(figsize=(5,4))\n",
    "\n",
    "\n",
    "title('Tests - average error = {}'.format(mean(squared_errors).round(4)))\n",
    "\n",
    "\n",
    "# Show points\n",
    "ax = scatter(*P.T, s = 2,  c = y, edgecolors='none', zorder = 2, cmap = cm.coolwarm )\n",
    "\n",
    "#limits\n",
    "xlim( [lower_bound[0], upper_bound[0]] )\n",
    "ylim( [lower_bound[1], upper_bound[1]] )\n",
    "xlabel(\"$p_1$\", size = 'xx-large')\n",
    "ylabel(\"$p_2$\", size = 'xx-large')\n",
    "show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "css": [
   ""
  ],
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
